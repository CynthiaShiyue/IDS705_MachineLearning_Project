{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be17f97",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Severe Drop\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Apply to both train and test data\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDAMAGE_SEVERITY_CLASS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPCT_PRICE_CHANGE_DETRENDED\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(assign_damage_severity)\n\u001b[1;32m     23\u001b[0m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDAMAGE_SEVERITY_CLASS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPCT_PRICE_CHANGE_DETRENDED\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(assign_damage_severity)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# ======= Step 2: 准备特征和标签 =======\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 选择你的特征列（这里假设Baseline特征）\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "# ======= Step 0: 导入需要的库 =======\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ======= Step 1:  数据准备+参数设置 =======\n",
    "\n",
    "data = pd.read_csv(\"xgboost_data.csv\")\n",
    "\n",
    "# Configuration\n",
    "TARGET_VARIABLE = 'PCT_PRICE_CHANGE_DETRENDED (%)'\n",
    "RAW_TARGET_VARIABLE = 'PCT_PRICE_CHANGE (%)'\n",
    "YEAR_COLUMN = 'YEAR'\n",
    "ZIP_COLUMN = 'ZIP_CODE'\n",
    "TRAIN_YEAR_CUTOFF = 2020\n",
    "\n",
    "# XGBoost specific params\n",
    "XGB_PARAMS = {\n",
    "    'objective': 'multi:softprob', \n",
    "    'num_class': 3,\n",
    "    'eval_metric':'merror',\n",
    "    'n_estimators': 100,           \n",
    "    'learning_rate': 0.1,       \n",
    "    'max_depth': 5,                \n",
    "    'subsample': 0.8,             \n",
    "    'colsample_bytree': 0.8,       \n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1                   \n",
    "}\n",
    "\n",
    "# Step 1: Detrending Target Variable\n",
    "print(\"--- Detrending Target Variable ---\")\n",
    "# Ensure YEAR is numeric\n",
    "data[YEAR_COLUMN] = pd.to_numeric(data[YEAR_COLUMN], errors='coerce')\n",
    "data = data.dropna(subset=[YEAR_COLUMN, RAW_TARGET_VARIABLE]) # Drop rows where year or target is missing\n",
    "\n",
    "trend_model = LinearRegression()\n",
    "# Reshape YEAR for sklearn compatibility\n",
    "trend_model.fit(data[[YEAR_COLUMN]], data[RAW_TARGET_VARIABLE])\n",
    "predicted_trend = trend_model.predict(data[[YEAR_COLUMN]])\n",
    "data[TARGET_VARIABLE] = data[RAW_TARGET_VARIABLE] - predicted_trend\n",
    "print(f\"Target variable '{TARGET_VARIABLE}' created.\")\n",
    "print(f\"Target variable mean: {data[TARGET_VARIABLE].mean():.4f}, std: {data[TARGET_VARIABLE].std():.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# step2: 创建新的Severity分类标签 + 数据分离\n",
    "\n",
    "def assign_damage_severity(pct_change):\n",
    "    if pct_change > -5:\n",
    "        return 0  # Small Drop\n",
    "    elif -10 < pct_change <= -5:\n",
    "        return 1  # Medium Drop\n",
    "    else:\n",
    "        return 2  # Severe Drop\n",
    "\n",
    "data['DAMAGE_SEVERITY_CLASS'] = data[TARGET_VARIABLE].apply(assign_damage_severity)\n",
    "# Train/Test Split based on YEAR\n",
    "train_df = data[data[YEAR_COLUMN] <= TRAIN_YEAR_CUTOFF]\n",
    "test_df = data[data[YEAR_COLUMN] > TRAIN_YEAR_CUTOFF]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329ddfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply to both train and test data\n",
    "train_df[\"DAMAGE_SEVERITY_CLASS\"] = train_df[\"PCT_PRICE_CHANGE_DETRENDED\"].apply(\n",
    "    assign_damage_severity\n",
    ")\n",
    "test_df[\"DAMAGE_SEVERITY_CLASS\"] = test_df[\"PCT_PRICE_CHANGE_DETRENDED\"].apply(\n",
    "    assign_damage_severity\n",
    ")\n",
    "\n",
    "# ======= Step 2: 准备特征和标签 =======\n",
    "\n",
    "# 选择你的特征列（这里假设Baseline特征）\n",
    "feature_cols = [\n",
    "    \"Median_Household_Income\",\n",
    "    \"Total_Population\",\n",
    "    \"Avg_Household_Size\",\n",
    "    \"Gini_Index\",\n",
    "    \"Employment_Rate\",\n",
    "    \"Below_Poverty_Rate\",\n",
    "    \"Rate_College_or_Higher\",\n",
    "    \"Black_Population_Share\",\n",
    "    \"White_Population_Share\",\n",
    "    \"Asian_Population_Share\",\n",
    "    \"Native_Population_Share\",\n",
    "    \"HOME_PRICE_LAG1\",\n",
    "    \"PRICE_CHANGE_LAG1\",\n",
    "    \"PRICE_CHANGE_DIFF\",\n",
    "    \"ROLLING_1yr_PRICE_CHANGE\",\n",
    "    \"ROLLING_3yr_PRICE_CHANGE_STD\",\n",
    "]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df[\"DAMAGE_SEVERITY_CLASS\"]\n",
    "\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df[\"DAMAGE_SEVERITY_CLASS\"]\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ======= Step 3: 训练XGBoost多分类模型 =======\n",
    "\n",
    "model = XGBClassifier(\n",
    "    objective=\"multi:softprob\",  # 多分类 soft probability\n",
    "    num_class=3,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ======= Step 4: 预测并评估模型 =======\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 准确率\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Macro F1\n",
    "macro_f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test, y_pred, target_names=[\"Small Drop\", \"Medium Drop\", \"Severe Drop\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Confusion Matrix 可视化\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Small\", \"Medium\", \"Severe\"],\n",
    "    yticklabels=[\"Small\", \"Medium\", \"Severe\"],\n",
    ")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n",
    "\n",
    "# ======= Step 5: 可选 - 特征重要性 =======\n",
    "\n",
    "importances = model.feature_importances_\n",
    "importance_df = pd.DataFrame({\"Feature\": feature_cols, \"Importance\": importances})\n",
    "importance_df = importance_df.sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=\"Importance\", y=\"Feature\", data=importance_df)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
